{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "If you are going to just play with this script, I keep it in the baseline directory. Please add a -ignore to the end of the file, e.g. **explainability_inference-v1-kms-ignore** The -ignore will stop git from tracking the file. And you can play with it as much as you want. \n",
    "\n",
    "If you want to build on it and push a new version, please rename it e.g. **explainability_inference-v{ next version number }-{ your initials }-ignore** This way we can keep each iteration. These notebooks will have their own directory for work going forward. This is only for baseline model.\n",
    "\n",
    "You will need to hardcode some paths in here, I made a note where you shall do that. To use this notebook you also must have a model.h5 file (~100-200mbs) dont worry, the .gitignore will not let you commit or track a model file, but you will need it to work with this notebook. Model files can be found in the google drive either under baseline_model or model dirs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up & Sample Data Intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "from random import randint\n",
    "from configparser import ConfigParser\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "# tfe = tf.contrib.eager\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add you own path to your model here...\n",
    "model = models.load_model('DenseNet169_baseline_model.h5') # Load model, weights and meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_img(img_path):\n",
    "    img = image.load_img(img_path, target_size=(IMG_RESIZE_X, IMG_RESIZE_Y))\n",
    "    img_tensor = image.img_to_array(img)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0) #add batch dimension of 1 to image to match training shape\n",
    "    img_tensor /= 255.\n",
    "    return img_tensor\n",
    "\n",
    "def prepare_img(filename):\n",
    "    \"\"\"Prepare an image with the same preprocessing steps used during training (no augmentation)\"\"\"\n",
    "    image_string = tf.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=CHANNELS) # Don't use tf.image.decode_image\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) #convert to float values in [0, 1]\n",
    "    image = tf.image.resize_images(image, [IMG_RESIZE_X, IMG_RESIZE_Y])\n",
    "    image = image[np.newaxis,...]\n",
    "    print(\"Image size pushed into the network: \" + str(image.shape))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this test, we shall use the sample images in the repo, as this is a universal file path for all users\n",
    "data_path = '../../images/'\n",
    "img_names = ['neg_sample_1', 'neg_sample_2', 'pos_sample_1', 'pos_sample_2']\n",
    "img_type = '.png'\n",
    "IMG_RESIZE_X = 320\n",
    "IMG_RESIZE_Y = 320\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path = data_path + img_names[randint(0, 3)] + img_type #randomly select from the 4 sample images in the repo\n",
    "img = prepare_img(img_path)\n",
    "\n",
    "# plt the image we are predicting on\n",
    "image_to_plot = print_img(img_path)\n",
    "plt.imshow(image_to_plot[0])\n",
    "plt.show()\n",
    "\n",
    "print(\"Image being passed to network: \" + img_path[-16:])\n",
    "pred_prob = model.predict(img, batch_size=None, steps=1, verbose=1)\n",
    "print(pred_prob)\n",
    "pred_prob = np.where(pred_prob > 0.5, 1, 0)[0][0]\n",
    "print(pred_prob)\n",
    "if pred_prob == 0:\n",
    "    pred = 'Negative'\n",
    "else:\n",
    "    pred = 'Positive'\n",
    "print(\"Predict class: \" + pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on a Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_path = '/Users/keil/datasets/mura/' #Add you own path here...\n",
    "input_csv = 'MURA-v1.1/valid_image_paths.csv'\n",
    "output_csv = 'MURA-v1.1/predictions.csv' #predictions csv file saved to data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_generator(csv_line):\n",
    "    csv_line = csv_line.rstrip('\\n') #chomp chomp\n",
    "    split_line = csv_line.split('/') #tokenize line\n",
    "    patient = split_line[3][7:] #get the patient number\n",
    "    study = re.search(r'([0-9]+)',split_line[4]).group(0) #get the study number\n",
    "    record = patient + '/' + study #create unique patient study record\n",
    "    return csv_line, record\n",
    "\n",
    "patient_dict = {} #our new data study based structure key = patient_num/study_num e.g. 11185/1, 11185/2\n",
    "count = 0\n",
    "with open(full_data_path+input_csv,'r') as in_file:\n",
    "    buffer = []\n",
    "    previous_id = None\n",
    "    for line in in_file:\n",
    "        data, unique_id = id_generator(line) #sanitize data\n",
    "        \n",
    "        if previous_id == None: #special case for first loop\n",
    "            previous_id = unique_id\n",
    "        \n",
    "        if previous_id != unique_id: #write the buffers to the dict if a new patient and or study appear\n",
    "            patient_dict[previous_id] = buffer\n",
    "            buffer = [] #flush buffers\n",
    "            previous_id = unique_id\n",
    "        \n",
    "        buffer.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in patient_dict.items():\n",
    "    print(k,v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### patient_dict is a dictionary of image file path values grouped to keys which are patient_id + study_id, because a patient can have multiple studies, and each study (and thw study's image(s)) must be predicted in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit\n",
    "#collect memory usage for submission...\n",
    "\n",
    "def strip_filename(path):\n",
    "    dirname, filename = os.path.split(path)\n",
    "    return dirname + '/'\n",
    "\n",
    "def prepare_img(filename):\n",
    "    \"\"\"Prepare an image with the same preprocessing steps used during training (no augmentation)\"\"\"\n",
    "    image_string = tf.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=CHANNELS) # Don't use tf.image.decode_image\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) #convert to float values in [0, 1]\n",
    "    image = tf.image.resize_images(image, [IMG_RESIZE_X, IMG_RESIZE_Y])\n",
    "    image = image[np.newaxis,...] #add on that tricky batch axis\n",
    "    return image\n",
    "    \n",
    "def inference(img_path, model, data_path=full_data_path):\n",
    "    img = prepare_img(full_data_path+img_path)\n",
    "    pred_prob = model.predict(img, batch_size=None, steps=1, verbose=0)\n",
    "    return pred_prob[0][0]\n",
    "\n",
    "def avg_probabilities(prob_vector):\n",
    "    vec = np.array(prob_vector)\n",
    "    avg_prob = vec.sum()/len(prob_vector)\n",
    "    return int(np.where(avg_prob > 0.5, 1, 0))\n",
    "\n",
    "\n",
    "predictions = []\n",
    "count=0\n",
    "for patient_study_id, img_path_list in patient_dict.items():\n",
    "    prob_vector = []\n",
    "    dir_path = strip_filename(img_path_list[0])\n",
    "    for img_path in img_path_list:\n",
    "        pred = inference(img_path, model) #i'm sure we can do this as a batch, memory contraints???\n",
    "        prob_vector.append(pred)\n",
    "    count+=1\n",
    "    print(prob_vector)\n",
    "    classification = avg_probabilities(prob_vector)\n",
    "    predictions.append((dir_path, classification))\n",
    "    if count == 3:\n",
    "        break\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out the list of prediction tuples to a csv\n",
    "\n",
    "with open(full_data_path+output_csv,'w') as out_file:\n",
    "    writer = csv.writer(out_file)\n",
    "    for result in predictions:\n",
    "        writer.writerow([result[0],result[1]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Activation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_ouputs(model):\n",
    "    layer_outputs = [layer.output for layer in model.layers]\n",
    "    return layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = get_layer_ouputs(model)\n",
    "# Critical logic error: speciasl use of layer_outputs[1:] because [0] is model.input layer. Therefore the\n",
    "# layer is being fed and fetched will result in erra! O.o\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs[1:]) \n",
    "activations = activation_model.predict(img, batch_size=None, steps=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activation_layer(layer_num,model=activations,outputs=layer_outputs[1:]):\n",
    "    \"\"\"Get info on the activation layer\"\"\"\n",
    "    print(model[layer_num].shape)\n",
    "    print(\"output layer: \" + str(outputs[layer_num]))\n",
    "    return model[layer_num]\n",
    "\n",
    "print(len(activations)) # 595 activation map layers weee!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_layer = extract_activation_layer(100)\n",
    "#true layer 0: input layer ------ removed\n",
    "\n",
    "#layer 0: padding layer\n",
    "#layer 1: conv 2d layer\n",
    "#layer 2: batch norm\n",
    "#layer 3: relu activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(activation_layer[0, :, :, 220], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to get the layer information from the activation model:\n",
    "activation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot out many activation map thumbnails... RAISE TODO!!!\n",
    "\n",
    "for idx,layers in enumerate(layer_outputs):\n",
    "    m = re.search(r'\\w(conv)',str(layers))\n",
    "    if m:\n",
    "        print(\"yes\")\n",
    "        print(layers)\n",
    "        print(idx)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_maps = extract_activation_layer(1)\n",
    "imgs_per_row = 16\n",
    "num_cols = conv_maps.shape[-1]\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
